N.max <- unlist(N[j]) - 1,
N.min <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
N.max <- unlist(N[j]) - 1,
N.min <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
N.max <- unlist(N[j]) - 1,
N.min <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (av_it - j)
# Print progress
cat(
sprintf("Iteration %d: N = %d | Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified >= .001) {
cat(
sprintf("Iteration %d: %.1f%% of models required simplification (independent random effects) due to high attrition (too little observations) \n",
j, results$prop_simplified * 100)
)
} else if(results$prop_simplified < .001 & results$prop_simplified > 0) {
cat(
"< 0.1% of models required simplification (independent random effects) due to high attrition (too little observations) \n"
)
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == N.min + 1 | N.max == N.min) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f) \n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
} else {
for (i in 1:3){
# Re-initialize
N <- list()
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
pow <- 0              # initialize power
av_it <- round(log((N.max - N.min + 1), base=2)) # approximation of average numbers of iterations
N_min <- N.min
N_max <- N.max
# print info on sensitivity analysis
paste("\n", "Sensitivity analysis for fraction = ", i, "\n")
while(condition == F){
N[j] <- round((N.min + N.max)/2 - .1, digits = 0)  # current N is the mid point between N.min and N.max, rounded to the lower number
# set m according to iteration/difference between actual (pow) and desired power (eta)
if(m>=5000){
if(j==1 | abs(pow-eta) > .1){ # in the first iteration or if the difference between pow and eta is at least .1, set m to 1000
current_m <- 1000
} else {
current_m <- m
}
}
# generate data and store BFs
results <- get_power(attrition=attrition, params=params, m=current_m, N=unlist(N[j]),
log.grow=log.grow, fraction=i,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
N_max <- unlist(N[j]) - 1,
N_min <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
N_max <- unlist(N[j]) - 1,
N_min <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
N_max <- unlist(N[j]) - 1,
N_min <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (av_it - j) * (4-i)
# Print progress
cat(
sprintf("Iteration %d: N = %d | Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified >= .001) {
cat(
sprintf("Iteration %d: %.1f%% of models required simplification (independent random effects) due to high attrition (too little observations) \n",
j, results$prop_simplified * 100)
)
} else if(results$prop_simplified < .001 & results$prop_simplified > 0) {
cat(
"< 0.1% of models required simplification (independent random effects) due to high attrition (too little observations) \n"
)
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == N_min + 1 | N_max == N_min) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f) \n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
}
}
# in case of interruption
}, interrupt = function(e) {
message("Interrupt detected - resetting parallel processing plan")
future::plan(future::sequential)
}, error = function(e) {
message("Error detected - resetting parallel processing plan")
future::plan(future::sequential)
stop(e)  # Re-throw the error
})
}
BayeSSD(seed=123, m=1000, hypothesis="a=b=c", eff.sizes = c(0,0,0), sensitivity = T)
BayeSSD <- function(eta=.8, attrition="weibull", params=c(.5,1),
m=10000, t.points=c(0,1,2,3,4), var.u0=0.01,
var.u1=.1, var.e=.01, cov=0, eff.sizes=c(0, .5, .8),
BFthres=5, fraction=1, log.grow=F, seed=NULL,
hypothesis="a<b<c", PMPthres=.9, sensitivity=F, tol=.01,
N.max=1000, N.min=30, method="bfc") {
# Use calling handlers to catch interrupts
withCallingHandlers({
# error and warning messages in case of incorrect input
if(eta<0 | eta>1) {stop("'eta' (the desired power level) must be between 0 and 1.")}
if(m%%1!=0 | m<1) {stop("'m' must be a positive integer.")}
if(!is.logical(log.grow)) {stop("'log.grow' must be either TRUE or FALSE.")}
if(is.logical(sensitivity)==F) {stop("'sensitivity' must be either TRUE or FALSE.")}
if(any(t.points<0)) {stop("all time points must be positive.")}
if(var.u0<0 | var.u1<0 | var.e<0) {stop("all variance components must be positive.")}
if(BFthres<0) {stop("'BFthres' must be positive.")}
if(fraction%%1!=0 | fraction<1) {stop("'fraction' must be a positive integer, b=fraction/N.")}
if(m<1000) {message("Results with less than 1000 generated datasets per iteration can be unreliable.")}
if((method=="bf" | method=="BF") & (length(hypothesis)!=2)) {stop("Method 'bf' requires exactly two hypotheses.")}
start_time <- Sys.time()
if(!is.null(seed)) {set.seed(seed)}  # set user-specified seed for reproducibility
N <- list()
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
pow <- 0              # initialize power
av_it <- round(log((N.max - N.min + 1), base=2)) # approximation of average numbers of iterations
if(sensitivity==F){
while(condition == F){
N[j] <- round((N.min + N.max)/2 - .1, digits = 0)  # current N is the mid point between N.min and N.max, rounded to the lower number
# set m according to iteration/difference between actual (pow) and desired power (eta)
if(m>=5000){
if(j==1 | abs(pow-eta) > .1){ # in the first iteration or if the difference between pow and eta is at least .1, set m to 1000
current_m <- 1000
} else {
current_m <- m
}
}
# generate data and store BFs
results <- get_power(attrition=attrition, params=params, m=current_m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
N.max <- unlist(N[j]) - 1,
N.min <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
N.max <- unlist(N[j]) - 1,
N.min <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
N.max <- unlist(N[j]) - 1,
N.min <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (av_it - j)
# Print progress
cat(
sprintf("Iteration %d: N = %d | Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified >= .001) {
cat(
sprintf("Iteration %d: %.1f%% of models required simplification (independent random effects) due to high attrition (too little observations) \n",
j, results$prop_simplified * 100)
)
} else if(results$prop_simplified < .001 & results$prop_simplified > 0) {
cat(
"< 0.1% of models required simplification (independent random effects) due to high attrition (too little observations) \n"
)
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == N.min + 1 | N.max == N.min) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f) \n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
} else {
for (i in 1:3){
# Re-initialize
N <- list()
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
pow <- 0              # initialize power
av_it <- round(log((N.max - N.min + 1), base=2)) # approximation of average numbers of iterations
N_min <- N.min
N_max <- N.max
# print info on sensitivity analysis
cat("\n", "Sensitivity analysis for fraction = ", i, "\n")
while(condition == F){
N[j] <- round((N.min + N.max)/2 - .1, digits = 0)  # current N is the mid point between N.min and N.max, rounded to the lower number
# set m according to iteration/difference between actual (pow) and desired power (eta)
if(m>=5000){
if(j==1 | abs(pow-eta) > .1){ # in the first iteration or if the difference between pow and eta is at least .1, set m to 1000
current_m <- 1000
} else {
current_m <- m
}
}
# generate data and store BFs
results <- get_power(attrition=attrition, params=params, m=current_m, N=unlist(N[j]),
log.grow=log.grow, fraction=i,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
N_max <- unlist(N[j]) - 1,
N_min <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
N_max <- unlist(N[j]) - 1,
N_min <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
N_max <- unlist(N[j]) - 1,
N_min <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (av_it - j) * (4-i)
# Print progress
cat(
sprintf("Iteration %d: N = %d | Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified >= .001) {
cat(
sprintf("Iteration %d: %.1f%% of models required simplification (independent random effects) due to high attrition (too little observations) \n",
j, results$prop_simplified * 100)
)
} else if(results$prop_simplified < .001 & results$prop_simplified > 0) {
cat(
"< 0.1% of models required simplification (independent random effects) due to high attrition (too little observations) \n"
)
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == N_min + 1 | N_max == N_min) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f) \n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
}
}
# in case of interruption
}, interrupt = function(e) {
message("Interrupt detected - resetting parallel processing plan")
future::plan(future::sequential)
}, error = function(e) {
message("Error detected - resetting parallel processing plan")
future::plan(future::sequential)
stop(e)  # Re-throw the error
})
}
BayeSSD(seed=123, m=1000, hypothesis="a=b=c", eff.sizes = c(0,0,0), sensitivity = T)
BayeSSD <- function(eta=.8, attrition="weibull", params=c(.5,1),
m=10000, t.points=c(0,1,2,3,4), var.u0=0.01,
var.u1=.1, var.e=.01, cov=0, eff.sizes=c(0, .5, .8),
BFthres=5, fraction=1, log.grow=F, seed=NULL,
hypothesis="a<b<c", PMPthres=.9, sensitivity=F, tol=.01,
N.max=1000, N.min=30, method="bfc") {
# Use calling handlers to catch interrupts
withCallingHandlers({
# error and warning messages in case of incorrect input
if(eta<0 | eta>1) {stop("'eta' (the desired power level) must be between 0 and 1.")}
if(m%%1!=0 | m<1) {stop("'m' must be a positive integer.")}
if(!is.logical(log.grow)) {stop("'log.grow' must be either TRUE or FALSE.")}
if(is.logical(sensitivity)==F) {stop("'sensitivity' must be either TRUE or FALSE.")}
if(any(t.points<0)) {stop("all time points must be positive.")}
if(var.u0<0 | var.u1<0 | var.e<0) {stop("all variance components must be positive.")}
if(BFthres<0) {stop("'BFthres' must be positive.")}
if(fraction%%1!=0 | fraction<1) {stop("'fraction' must be a positive integer, b=fraction/N.")}
if(m<1000) {message("Results with less than 1000 generated datasets per iteration can be unreliable.")}
if((method=="bf" | method=="BF") & (length(hypothesis)!=2)) {stop("Method 'bf' requires exactly two hypotheses.")}
start_time <- Sys.time()
if(!is.null(seed)) {set.seed(seed)}  # set user-specified seed for reproducibility
N <- list()
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
pow <- 0              # initialize power
av_it <- round(log((N.max - N.min + 1), base=2)) # approximation of average numbers of iterations
if(sensitivity==F){
while(condition == F){
N[j] <- round((N.min + N.max)/2 - .1, digits = 0)  # current N is the mid point between N.min and N.max, rounded to the lower number
# set m according to iteration/difference between actual (pow) and desired power (eta)
if(m>=5000){
if(j==1 | abs(pow-eta) > .1){ # in the first iteration or if the difference between pow and eta is at least .1, set m to 1000
current_m <- 1000
} else {
current_m <- m
}
}
# generate data and store BFs
results <- get_power(attrition=attrition, params=params, m=current_m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
N.max <- unlist(N[j]) - 1,
N.min <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
N.max <- unlist(N[j]) - 1,
N.min <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
N.max <- unlist(N[j]) - 1,
N.min <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (av_it - j)
# Print progress
cat(
sprintf("Iteration %d: N = %d | Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified >= .001) {
cat(
sprintf("Iteration %d: %.1f%% of models required simplification (independent random effects) due to high attrition (too little observations) \n",
j, results$prop_simplified * 100)
)
} else if(results$prop_simplified < .001 & results$prop_simplified > 0) {
cat(
"< 0.1% of models required simplification (independent random effects) due to high attrition (too little observations) \n"
)
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == N.min + 1 | N.max == N.min) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f) \n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
} else {
for (i in 1:3){
# Re-initialize
N <- list()
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
pow <- 0              # initialize power
av_it <- round(log((N.max - N.min + 1), base=2)) # approximation of average numbers of iterations
N_min <- N.min
N_max <- N.max
# print info on sensitivity analysis
cat("\n", "Sensitivity analysis for fraction = ", i, "\n")
while(condition == F){
N[j] <- round((N_min + N_max)/2 - .1, digits = 0)  # current N is the mid point between N.min and N.max, rounded to the lower number
# set m according to iteration/difference between actual (pow) and desired power (eta)
if(m>=5000){
if(j==1 | abs(pow-eta) > .1){ # in the first iteration or if the difference between pow and eta is at least .1, set m to 1000
current_m <- 1000
} else {
current_m <- m
}
}
# generate data and store BFs
results <- get_power(attrition=attrition, params=params, m=current_m, N=unlist(N[j]),
log.grow=log.grow, fraction=i,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
N_max <- unlist(N[j]) - 1,
N_min <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
N_max <- unlist(N[j]) - 1,
N_min <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
N_max <- unlist(N[j]) - 1,
N_min <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (av_it - j) * (4-i)
# Print progress
cat(
sprintf("Iteration %d: N = %d | Power = %.3f | Elapsed: %.1f minutes | Total remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified >= .001) {
cat(
sprintf("Iteration %d: %.1f%% of models required simplification (independent random effects) due to high attrition (too little observations) \n",
j, results$prop_simplified * 100)
)
} else if(results$prop_simplified < .001 & results$prop_simplified > 0) {
cat(
"< 0.1% of models required simplification (independent random effects) due to high attrition (too little observations) \n"
)
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == N_min + 1 | N_max == N_min) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f) \n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
}
}
# in case of interruption
}, interrupt = function(e) {
message("Interrupt detected - resetting parallel processing plan")
future::plan(future::sequential)
}, error = function(e) {
message("Error detected - resetting parallel processing plan")
future::plan(future::sequential)
stop(e)  # Re-throw the error
})
}
BayeSSD(seed=123, m=1000, hypothesis="a=b=c", eff.sizes = c(0,0,0), sensitivity = T)
getwd()
usethis::use_package_doc()
devtools::document()
The accompanying paper for the `BayesSSD` package authored by Ulrich Lösener and Mirjam Moerbeek is called "Bayesian Sample Size Determination for Longitudinal Trials with Attrition - the BayesSSD Package" and has been submitted to Psychological Methods.
For questions or feedback, please contact me under u.c.losener1@uu.nl.
usethis::use_readme_rmd()
